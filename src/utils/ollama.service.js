const axios = require('axios');

const logger = require('../../../utils/logger.utils');
const { REPORT_PROMPT } = require('./prompts');

// ğŸ”¥ Ø·Ø§Ø¨ÙˆØ± Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø±: Ù„Ø¶Ù…Ø§Ù† Ø¹Ø¯Ù… ØªØ´ØºÙŠÙ„ Ø£ÙƒØ«Ø± Ù…Ù† Ø¹Ù…Ù„ÙŠØ© AI ÙÙŠ Ù†ÙØ³ Ø§Ù„ÙˆÙ‚Øª
let requestQueue = Promise.resolve();

exports.generateReportContent = async (targetUrl, cleanedData) => {
    // Ù†Ø±Ø¨Ø· Ø§Ù„Ø·Ù„Ø¨ Ø§Ù„Ø­Ø§Ù„ÙŠ Ø¨Ù†Ù‡Ø§ÙŠØ© Ø§Ù„Ø·Ù„Ø¨ Ø§Ù„Ø³Ø§Ø¨Ù‚ ÙÙŠ Ø§Ù„Ø·Ø§Ø¨ÙˆØ±
    const currentTask = async () => {
    
    // 1. Ù‡Ù†Ø¯Ø³Ø© Ø§Ù„Ø£ÙˆØ§Ù…Ø± (Ù†Ø³Ø®Ø© Ø§Ù„Ù…Ù‚Ø§Ù„ Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠ)
    const today = new Date().toISOString().split('T')[0];
    const prompt = REPORT_PROMPT
        .replace('{{DATA}}', JSON.stringify(cleanedData, null, 2))
        .replace('{{TARGET_URL}}', targetUrl)
        .replace('{{DATE}}', today)
        .replace('{{END_DATE}}', today)
        .replace('{{TIMESTAMP}}', Date.now().toString());

    try {
        if (logger) logger.info(`ğŸ¤– Generating Professional Security Report (Balanced Mode) for: ${targetUrl}`);
        const startTime = Date.now();

        // Ø­Ø³Ø§Ø¨ ØªÙ‚Ø±ÙŠØ¨ÙŠ Ù„Ø­Ø¬Ù… Ø§Ù„Ø¯Ø§ØªØ§
        const dataStr = JSON.stringify(cleanedData);
        if (dataStr.length > 10000) if (logger) logger.warn("âš ï¸ Heavy Input Data: Processing might take extra time.");

        const response = await axios.post('http://localhost:11434/api/generate', {
            model: "llama3.1:8b-instruct-q4_0", 
            prompt: prompt,
            stream: false,
            
            // ğŸ¯ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù…ØªÙˆØ§Ø²Ù†Ø© Ù„Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ù…Ù†ÙŠ Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠ
            // Ø§Ù„Ù‡Ø¯Ù: ØªÙ‚Ø±ÙŠØ± Ù…ÙØµÙ‘Ù„ ÙˆØ´Ø§Ù…Ù„ Ù…Ø¹ Ø³Ø±Ø¹Ø© Ù…Ø¹Ù‚ÙˆÙ„Ø©
            options: { 
                // 1. ğŸ“Š Ø§Ù„Ø°Ø§ÙƒØ±Ø© (ÙƒØ§ÙÙŠØ© Ù„ØªØ­Ù„ÙŠÙ„ Ø«ØºØ±Ø§Øª Ù…ØªØ¹Ø¯Ø¯Ø©)
                num_ctx: 2048,         // âš¡ Ù…Ù†Ø§Ø³Ø¨Ø© Ù„ØªØ­Ù„ÙŠÙ„ 3-5 Ø«ØºØ±Ø§Øª Ø¨ØªÙØµÙŠÙ„
                
                // 2. ğŸ”¥ GPU: ØªÙˆØ§Ø²Ù† Ø¨ÙŠÙ† Ø§Ù„Ø£Ø¯Ø§Ø¡ ÙˆØ§Ù„Ø§Ø³ØªÙ‚Ø±Ø§Ø±
                num_gpu: 18,           // âš¡ 18 Ø·Ø¨Ù‚Ø© = Ø¬ÙˆØ¯Ø© Ø¹Ø§Ù„ÙŠØ© Ù…Ø¹ Ø§Ø³ØªÙ‚Ø±Ø§Ø±
                
                // 3. ğŸ¯ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø¬ÙˆØ¯Ø© (Ù…ÙØ­Ø³Ù‘Ù†Ø© Ù„Ù„ØªÙ‚Ø§Ø±ÙŠØ± Ø§Ù„Ø£Ù…Ù†ÙŠØ©)
                temperature: 0.2,      // Ù…Ù†Ø®ÙØ¶Ø© Ù„Ù„Ø¯Ù‚Ø© ÙˆØ§Ù„Ø§Ù„ØªØ²Ø§Ù… Ø¨Ø§Ù„Ù‚Ø§Ù„Ø¨
                top_p: 0.9,            // Ù†Ø·Ø§Ù‚ ÙˆØ§Ø³Ø¹ Ù„Ù„ØªØ¹Ø¨ÙŠØ±Ø§Øª Ø§Ù„ÙÙ†ÙŠØ©
                top_k: 50,             // ØªÙˆØ§Ø²Ù† Ø¨ÙŠÙ† Ø§Ù„ØªÙ†ÙˆØ¹ ÙˆØ§Ù„Ø¯Ù‚Ø©
                repeat_penalty: 1.2,   // Ù…Ù†Ø¹ Ø§Ù„ØªÙƒØ±Ø§Ø± ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„
                
                // 4. ğŸ“ Ø­Ø¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª (Ù…Ø±Ù† Ù„Ù„ØªÙ‚Ø§Ø±ÙŠØ± Ø§Ù„Ù…ÙØµÙ„Ø©)
                num_thread: 4,         
                num_predict: 3500,     // âš¡ ÙƒØ§ÙÙŠ Ù„ØªØ­Ù„ÙŠÙ„ 5-7 Ø«ØºØ±Ø§Øª Ø¨ØªÙØµÙŠÙ„ ÙƒØ§Ù…Ù„
                
                // 5. ğŸ”¥ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù…ØªÙˆØ§Ø²Ù†Ø©
                num_batch: 512,        // ØªÙˆØ§Ø²Ù† Ø¨ÙŠÙ† Ø§Ù„Ø³Ø±Ø¹Ø© ÙˆØ§Ø³ØªÙ‡Ù„Ø§Ùƒ VRAM
                use_mmap: true,        
                use_mlock: false,      
                num_keep: 6,           // Ø§Ù„Ø§Ø­ØªÙØ§Ø¸ Ø¨Ø³ÙŠØ§Ù‚ Ø£ÙƒØ¨Ø± Ù„Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ØªØ±Ø§Ø¨Ø·
                
                // 6. ğŸ¯ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ© Ù„Ù„Ø¬ÙˆØ¯Ø©
                presence_penalty: 0.1, // ØªØ´Ø¬ÙŠØ¹ Ø§Ù„ØªÙ†ÙˆØ¹ ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„
                frequency_penalty: 0.1 // ØªØ¬Ù†Ø¨ ØªÙƒØ±Ø§Ø± Ù†ÙØ³ Ø§Ù„Ø¹Ø¨Ø§Ø±Ø§Øª
            } 
        }, {
            timeout: 900000,  // 15 Ø¯Ù‚ÙŠÙ‚Ø© - ÙˆÙ‚Øª ÙƒØ§ÙÙŠ Ù„Ù„ØªÙ‚Ø§Ø±ÙŠØ± Ø§Ù„Ù…ÙØµÙ„Ø©
            maxContentLength: Infinity,
            maxBodyLength: Infinity
        });

        if (response.data && response.data.response) {
            const duration = ((Date.now() - startTime) / 1000).toFixed(2);
            if (logger) logger.info(`âœ… Security Report Generated Successfully (Balanced Mode) in ${duration}s ğŸ¯`);
            console.log(`ğŸ¯ AI Analysis Time: ${duration}s (Quality-Optimized for Security Reports)`);
            
            const timestamp = new Date().toLocaleString('en-US', { timeZone: 'Africa/Cairo' });
            
            const reportWithMetadata = `---
Report Generated: ${timestamp}
Target: ${targetUrl}
Analysis Engine: VulnCraft AI (Quality-Balanced Architecture)
Processing Time: ${duration}s
Report Quality: Professional Security Analysis
Confidentiality: Internal / Restricted
---

${response.data.response}

---
<div align="center">
<strong>VulnCraft Project</strong> â€¢ <em>Next-Gen Security Analysis</em>
</div>
`;
            return reportWithMetadata;
        } else {
            throw new Error("Received empty response from AI Model");
        }

    } catch (error) {
        const errMsg = error.message;
        
        if (errMsg.includes("404")) {
            console.error("âŒ Model not found! Run: ollama pull llama3.1:8b-instruct-q4_0");
        } else if (errMsg.includes("timeout")) {
            console.error("â±ï¸ Timeout! Your report might be too complex.");
            console.error("   Solutions:");
            console.error("   1. This is normal for 7+ vulnerabilities");
            console.error("   2. Current timeout: 15 minutes");
            console.error("   3. Consider splitting large scans");
        } else if (errMsg.includes("out of memory") || errMsg.includes("CUDA") || errMsg.includes("OOM")) {
            console.error("ğŸ’¾ GPU Out of Memory! Solutions:");
            console.error("   1. Change num_gpu from -1 to 25");
            console.error("   2. Reduce num_ctx to 1536");
            console.error("   3. Reduce num_batch to 1024");
            console.error("   4. Close Chrome and other GPU apps");
            console.error("   5. Run: nvidia-smi to check VRAM usage");
        }
        
        if (logger && logger.error) logger.error(`AI Service Error: ${errMsg}`);
        else console.error("Full Error:", errMsg);
        
        return `# Report Generation Failed
**Target:** ${targetUrl}
**Error:** AI Processing Error (GPU Turbo Mode)
**Details:** ${errMsg}

**Speed Optimization Tips:**
1. Model: llama3.1:8b-instruct-q4_0 âœ…
2. Close all GPU apps (Chrome, games)
3. Run 'nvidia-smi' to monitor VRAM
4. Current settings: num_ctx=2048, num_batch=2048

**If OOM occurs:**
- Edit code: num_gpu: 25 (instead of -1)
- Reduce: num_ctx: 1536
- Reduce: num_batch: 1024`;
    }
    };

    const result = requestQueue.then(currentTask);
    requestQueue = result.catch(() => {});

    return result;
};